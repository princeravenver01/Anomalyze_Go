# Anomalyze ğŸ”

**High-Performance Network Intrusion Detection System using Machine Learning**

Anomalyze is an optimized network anomaly detection system that uses ensemble K-means clustering to identify suspicious network traffic patterns and potential cyber threats with exceptional speed and accuracy.

![Python](https://img.shields.io/badge/python-v3.12+-blue.svg)
![Flask](https://img.shields.io/badge/flask-v3.0+-green.svg)
![scikit-learn](https://img.shields.io/badge/scikit--learn-v1.5+-orange.svg)
![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Deployment](https://img.shields.io/badge/deployment-Render%20%2B%20Vercel-blueviolet.svg)

## ğŸ—ï¸ Architecture

Anomalyze uses a modern split architecture for optimal performance and scalability:

```
User â†’ Vercel (Frontend) â†’ Render (API + ML Models) â†’ Results
```

- **Vercel**: Hosts the web interface and handles user interactions
- **Render**: Hosts ML models, training data, and provides prediction API
- **Benefits**: Independent scaling, cost-effective, easy maintenance

## ğŸš€ Key Features

- **âš¡ Ultra-Fast Processing**: 47,000+ samples per second processing speed
- **ğŸ¯ High Accuracy**: 86.24% accuracy with 87.17% F1-score
- **ğŸ”„ Optimized K-means Ensemble**: 5 different K-means models with optimized configurations
- **ğŸ“Š Real-time Analysis**: Instant anomaly detection results via REST API
- **ğŸ“ˆ Comprehensive Metrics**: Detailed performance analytics with precision, recall, and confidence scoring
- **ğŸ¨ User-Friendly Interface**: Clean web application deployed on Vercel
- **âš™ï¸ Streamlined Preprocessing**: Optimized data pipeline for maximum performance
- **ğŸ“‹ KDD Cup 1999 Compatible**: Industry-standard dataset support
- **â˜ï¸ Cloud-Native**: Deployed on Render and Vercel for reliability

## ğŸ† Performance Highlights

| Metric               | Value              | Status       |
| -------------------- | ------------------ | ------------ |
| **Processing Speed** | 47,137 samples/sec | âš¡ Excellent |
| **Accuracy**         | 86.24%             | ğŸ¯ Excellent |
| **Precision**        | 92.86%             | ğŸ” Very High |
| **Recall**           | 82.15%             | ğŸ“Š High      |
| **F1-Score**         | 87.17%             | ğŸª Excellent |
| **API Response**     | <1 second          | âš¡ Fast      |

## ğŸ› ï¸ Technology Stack

### Backend (Render)

- **Runtime**: Python 3.12
- **Framework**: Flask 3.0+ with Flask-CORS
- **ML Libraries**: scikit-learn 1.5+, NumPy 1.26+, Pandas 2.2+
- **Server**: Gunicorn
- **Storage**: Models and training data included

### Frontend (Vercel)

- **Runtime**: Python 3.12
- **Framework**: Flask 3.0+
- **HTTP Client**: Requests
- **Deployment**: Serverless functions

## ğŸ“ Project Structure

```
Anomalyze/
â”œâ”€â”€ api_server.py              # Render API backend
â”œâ”€â”€ app_vercel.py              # Vercel frontend
â”œâ”€â”€ app.py                     # Original standalone app
â”œâ”€â”€ requirements-render.txt    # API dependencies
â”œâ”€â”€ requirements-vercel.txt    # Frontend dependencies
â”œâ”€â”€ requirements.txt           # All dependencies
â”œâ”€â”€ render.yaml                # Render configuration
â”œâ”€â”€ vercel.json                # Vercel configuration
â”œâ”€â”€ runtime.txt                # Python version
â”œâ”€â”€ models/                    # ML models (for Render)
â”‚   â”œâ”€â”€ ensemble_models.joblib
â”‚   â”œâ”€â”€ scaler.joblib
â”‚   â”œâ”€â”€ data_columns.joblib
â”‚   â””â”€â”€ optimal_threshold.joblib
â”œâ”€â”€ data/                      # Training data (for Render)
â”‚   â””â”€â”€ KDDTrain+.txt
â”œâ”€â”€ utils/                     # Shared utilities
â”‚   â””â”€â”€ preprocessing.py
â”œâ”€â”€ templates/                 # HTML templates
â”‚   â””â”€â”€ index.html
â”œâ”€â”€ static/                    # CSS/JS files
â”‚   â””â”€â”€ style.css
â””â”€â”€ docs/                      # Documentation
    â”œâ”€â”€ DEPLOYMENT.md
    â”œâ”€â”€ QUICKSTART.md
    â”œâ”€â”€ ARCHITECTURE.md
    â””â”€â”€ PRE_DEPLOYMENT_CHECKLIST.md
```

## ğŸš€ Quick Start

### Option 1: Deploy to Cloud (Recommended)

**Prerequisites:**

- GitHub account
- Render account (free tier available)
- Vercel account (free tier available)

**Steps:**

1. Clone this repository
2. Follow **[QUICKSTART.md](QUICKSTART.md)** for 3-step deployment
3. Your app will be live in ~15 minutes!

### Option 2: Run Locally

#### Run API Server

```bash
# Install dependencies
pip install -r requirements-render.txt

# Start API server
python api_server.py
```

API available at `http://localhost:10000`

#### Run Frontend

```bash
# Install dependencies
pip install -r requirements-vercel.txt

# Set API URL (Windows PowerShell)
$env:ANOMALYZE_API_URL="http://localhost:10000"

# Set API URL (Linux/Mac)
export ANOMALYZE_API_URL="http://localhost:10000"

# Start frontend
python app_vercel.py
```

Frontend available at `http://localhost:5000`

#### Run Standalone (Original)

```bash
pip install -r requirements.txt
python app.py
```

## ğŸ“š Documentation

- **[QUICKSTART.md](QUICKSTART.md)** - Quick 3-step deployment guide
- **[DEPLOYMENT.md](DEPLOYMENT.md)** - Comprehensive deployment instructions
- **[ARCHITECTURE.md](ARCHITECTURE.md)** - System architecture diagrams
- **[DEPLOYMENT_SUMMARY.md](DEPLOYMENT_SUMMARY.md)** - Deployment overview
- **[PRE_DEPLOYMENT_CHECKLIST.md](PRE_DEPLOYMENT_CHECKLIST.md)** - Pre-deployment checklist

## ğŸ”Œ API Endpoints

### Render API

```
GET  /health
     â””â”€â–º Health check and status

GET  /api/model-info
     â””â”€â–º Get model information

POST /api/predict
     â””â”€â–º File upload prediction (multipart/form-data)

POST /api/predict-json
     â””â”€â–º JSON data prediction
```

### Example API Usage

```bash
# Health check
curl https://your-api.onrender.com/health

# Predict from file
curl -X POST https://your-api.onrender.com/api/predict \
  -F "file=@network_data.txt"

# Predict from JSON
curl -X POST https://your-api.onrender.com/api/predict-json \
  -H "Content-Type: application/json" \
  -d '{"data": [{"duration": 0, "protocol_type": 1, ...}]}'
```

## ğŸ“Š Dataset

Uses the **NSL-KDD dataset** (improved version of KDD Cup 1999):

- Training: KDDTrain+.txt
- Testing: KDDTest.txt
- Features: 41 network traffic features
- Labels: Normal and various attack types

## ğŸ¯ Model Details

### Ensemble Configuration

- **5 K-Means models** with different configurations
- Cluster counts: 5, 8, 10 (with different random seeds)
- **Majority voting** for final predictions
- **Weighted confidence scoring**
- **Severity level classification**

### Features

- 20 most important features selected
- StandardScaler normalization
- Log transformation for skewed features
- Advanced network-specific features

## ğŸ”’ Security & Best Practices

- âœ… HTTPS enforced on both platforms
- âœ… CORS configured for secure cross-origin requests
- âœ… Environment variables for sensitive data
- âœ… Input validation on all endpoints
- âœ… Error handling without exposing internals
- âœ… Rate limiting recommended for production

## ğŸ’° Cost

### Free Tier (Available)

- **Render**: 750 hours/month, cold starts after 15min inactivity
- **Vercel**: 100GB bandwidth/month, 100 hours serverless execution
- **Total**: $0/month for moderate usage

### Paid Options

- **Render**: From $7/month (no cold starts, better performance)
- **Vercel**: From $20/month (more bandwidth, team features)

## ğŸ› Troubleshooting

**API not responding?**

- Check Render logs in dashboard
- Verify models folder exists in repository
- Free tier may have cold start delay (~30s)

**Frontend can't connect?**

- Verify `ANOMALYZE_API_URL` environment variable
- Check CORS settings in api_server.py
- Test API health endpoint directly

**Build failures?**

- Ensure Python 3.12 is specified
- Check all dependencies are compatible
- Review build logs for specific errors

See **[DEPLOYMENT.md](DEPLOYMENT.md)** for detailed troubleshooting.

## ğŸ“ˆ Performance Optimization

- Ensemble models provide robust predictions
- Optimized feature selection (20 features)
- Efficient preprocessing pipeline
- Fast StandardScaler transformation
- Minimal API overhead

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly (local and deployed)
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- NSL-KDD dataset creators
- scikit-learn community
- Flask framework
- Render and Vercel platforms

## ğŸ“ Support

- **Issues**: GitHub Issues
- **Documentation**: See `/docs` folder
- **Deployment Help**: See DEPLOYMENT.md

## ğŸ—ºï¸ Roadmap

- [ ] Add authentication for production use
- [ ] Implement rate limiting
- [ ] Add more visualization options
- [ ] Support for real-time streaming data
- [ ] Model retraining pipeline
- [ ] Extended dataset support

---

**Built with â¤ï¸ using Python 3.12, Flask, and Machine Learning**

**Ready to deploy?** â†’ Start with [QUICKSTART.md](QUICKSTART.md) ğŸš€
